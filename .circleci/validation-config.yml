version: 2.1

parameters:
  validate-opmon:
    type: boolean
    default: false
  validate-jetstream:
    type: boolean
    default: false
  validate-metrics:
    type: boolean
    default: false
  validate-looker:
    type: boolean
    default: false
  build-docs:
    type: boolean
    default: false
  base-revision:
    type: string
    default: << pipeline.git.base_revision >>
  validate-metric-config-parser:
    type: boolean
    default: false
  deploy-metric-config-parser:
    type: boolean
    default: false

executors:
  metric-config-parser-executor:
    docker:
    - image: python:3.10
    working_directory: ~/project/lib/metric-config-parser

jobs:
  validate-metrics:
    docker:
    - image: python:3.10
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - run:
        name: Build
        command: |
          pip install -r .script/requirements.txt
          pip install lib/metric-config-parser
    - &authenticate
      run:
        name: Authenticate to GCP
        command: |
          export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
          echo 'export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"' >> "$BASH_ENV"
          echo "$GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
    - run:
        name: Validate config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'definitions/*.toml' 'definitions/*.example.toml')
          echo "Run validation on changed files: "
          echo $changed_files
          python3 .script/validate.py $changed_files --config_repos='.'
  validate-opmon:
    docker:
    - image: gcr.io/moz-fx-data-experiments/opmon:latest
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - *authenticate
    - run:
        name: Validate OpMon config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'opmon/*.toml' 'opmon/*.toml.example')
          echo "Run validation on changed files: "
          echo $changed_files
          opmon validate_config --config_repos='.' --config_repos=opmon/ $changed_files
  validate-jetstream:
    docker:
    - image: gcr.io/moz-fx-data-experiments/jetstream:latest
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - *authenticate
    - run:
        name: Validate jetstream config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'jetstream/*.toml' 'jetstream/*.toml.example')
          echo "Run validation on changed files: "
          echo $changed_files
          jetstream validate_config --config_repos='.' --config_repos='jetstream/' $changed_files
  validate-looker:
    docker:
    - image: python:3.10
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - run:
        name: Build
        command: |
          pip install -r .script/requirements.txt
          pip install lib/metric-config-parser
    - *authenticate
    - run:
        name: Validate config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'looker/*.toml' 'looker/*.example.toml')
          echo "Run validation on changed files: "
          echo $changed_files
          python3 .script/validate.py --config_repos='.' --config_repos=looker/ $changed_files
  build-metric-config-parser:
    executor: metric-config-parser-executor
    steps:
    - checkout:
        path: ~/project
    - restore_cache:
        keys:
          # when lock files change, use increasingly general patterns to restore cache
          - &cache_key
            python-packages-v2-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
          - python-packages-v2-{{ .Branch }}-{{ checksum "requirements.in" }}-
          - python-packages-v2-{{ .Branch }}-
          - python-packages-v2-
    - &build
      run:
        name: Build
        command: |
          python3.10 -m venv venv/
          venv/bin/python -m pip install --upgrade pip
          venv/bin/pip install --progress-bar off --upgrade -r requirements.txt
    - run:
        name: ruff
        command: venv/bin/ruff check metric_config_parser
    - run:
        name: ruff format
        command: venv/bin/ruff format --check metric_config_parser
    - run:
        name: Mypy
        command: venv/bin/mypy metric_config_parser
    - run:
        name: PyTest
        command: venv/bin/pytest --ruff --ignore=metric_config_parser/tests/integration/
    - save_cache:
        paths:
        - venv/
        key: *cache_key
  integration-metric-config-parser:
    executor: metric-config-parser-executor
    steps:
    - checkout:
        path: ~/project
    - *build
    - run:
        name: PyTest Integration Test
        command: |
          venv/bin/pytest --ruff metric_config_parser/tests/integration/
  build-docs:
    docker:
      - image: python:3.10
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: "95:33:49:57:f9:11:81:75:a4:46:74:19:c6:89:f4:1c"
      - run:
          name: Build and deploy docs
          command: |
            python3.10 -m venv venv/
            venv/bin/python -m pip install --upgrade pip
            venv/bin/pip install -r .script/requirements.txt
            venv/bin/pip install lib/metric-config-parser
            venv/bin/python3 .script/generate_docs.py \
              --output_dir=generated_docs/
            cd generated_docs/
            PATH="../venv/bin:$PATH" mkdocs gh-deploy \
              -m "[ci skip] Deployed {sha} with MkDocs version: {version}"
  rerun-jetstream:
    docker:
    - image: google/cloud-sdk
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - &skip_forked_pr
      run:
        name: Early return if this build is from a forked PR
        command: |
          if [ -n "$CIRCLE_PR_NUMBER" ]; then
            echo "Do not re-run analysis on forked PRs, so marking this step successful"
            circleci step halt
          fi
    - run:
        name: Authorize gcloud CLI
        command: |
          # required for parsing kubectl pod statuses
          apt-get install jq -y
          apt-get install uuid-runtime
          export USE_GKE_GCLOUD_AUTH_PLUGIN=True
          export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
          echo "$JETSTREAM_GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
          gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS
          gcloud config set project $GCLOUD_PROJECT
          gcloud container clusters get-credentials jetstream --zone us-central1-a --project $GCLOUD_PROJECT
    - run:
        name: Rerun jetstream
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'jetstream/*.toml' 'jetstream/*.toml.example')

          # determine slugs of configs that got changed; filter out outcomes and defaults
          params=""
          for config in $changed_files; do
            slug=${config##*/}
            slug="${slug%.*}"
            if [ -e jetstream/"$slug".toml ]; then
              params+="--experiment_slug=${slug} "
            fi
          done

          echo "Latest change affected these experiments:"
          echo $params

          # stop running instances so that they do not interfere
          uuid=`uuidgen`
          pod_identifier="jetstream-${uuid}"
          kubectl delete pod -l app=$pod_identifier

          commit_message=$(git log --format=oneline -n 1 $CIRCLE_SHA1)
          if [[ "$commit_message" == *"[ci rerun-skip]"* ]] || [[ "$commit_message" == *"[ci rerun_skip]"* ]] || [[ "$commit_message" == *"[ci skip-rerun]"* ]] || [[ "$commit_message" == *"[ci skip_rerun]"* ]]; then
            echo "Skip rerun for files:"
            echo $changed_files

            # start a new instance
            kubectl run $pod_identifier --image=gcr.io/moz-fx-data-experiments/jetstream -l app=$pod_identifier --restart=Never --command -- jetstream rerun-skip $(echo $params)
          else
            echo "Rerun changed files: "
            echo $changed_files

            # start a new instance
            kubectl run $pod_identifier --image=gcr.io/moz-fx-data-experiments/jetstream -l app=$pod_identifier --restart=Never --command -- jetstream rerun --argo --return-status --recreate-enrollments $(echo $params)
            # link to logs
            cur_date=`date -u +%FT%TZ`
            echo "Pod Logs: https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.project_id%3D%22moz-fx-data-experiments%22%0Aresource.labels.location%3D%22us-central1-a%22%0Aresource.labels.cluster_name%3D%22jetstream%22%0Aresource.labels.namespace_name%3D%22default%22?scrollTimestamp=$cur_date"
            echo "Analysis Errors can be accessed via Redash: https://sql.telemetry.mozilla.org/dashboard/jetstream-errors?p_experiment=%25"
            # wait for pod to finish and check status
          fi

          running=true
          while [ $running = true ]
          do
            echo "Wait for jetstream to finish"
            pod_status=`kubectl get pod -l app=$pod_identifier --no-headers -o custom-columns=":status.phase"`
            if [ $pod_status = 'Succeeded' ] || [ $pod_status = 'Failed' ]; then
              running=false
            fi
            sleep 10
          done
          # delete pod
          kubectl delete pod -l app=$pod_identifier
          if [ $pod_status = 'Failed' ]; then
            echo "Error when running jetstream. Check the logs for more information."
            exit 1
          elif [ $pod_status = 'Succeeded' ]; then
            echo "Jetstream successfully completed."
          else
            echo "Jetstream completed in unknown status. Please check the logs."
            echo "Analysis Errors can be accessed via Redash: https://sql.telemetry.mozilla.org/dashboard/jetstream-errors?p_experiment=%25"
            exit 1
          fi
  deploy-metric-config-parser:
    executor: metric-config-parser-executor
    steps:
      - checkout:
          path: ~/project
      - run:
          name: Check for package version change in last commit before proceeding.
          command: |
            if git diff main HEAD~1 pyproject.toml | grep 'version'
              then
                echo "Found changes to package version dir, proceeding with deployment."
              else
                echo "No changes in package version. Skipping metric-config-parser deployment."
                circleci-agent step halt
            fi
      - run:
          name: Install deployment tools
          command: |
            pip install --upgrade build setuptools wheel twine
      - run:
          name: Create the distribution files
          command: |
            python3.10 -m build --sdist
      - run:
          name: Upload to PyPI
          command: |
            # Relies on the TWINE_USERNAME and TWINE_PASSWORD environment variables configured at:
            #   https://circleci.com/gh/mozilla/metric-config-parser/edit#env-vars
            # For more on twine, see:
            #   https://twine.readthedocs.io/en/latest/
            twine upload --skip-existing dist/*
workflows:
  version: 2
  validate-metrics:
    when: 
      or: 
        - << pipeline.parameters.validate-metrics >>
    jobs:
      - validate-metrics
  validate-opmon:
    when: 
      or: 
        - << pipeline.parameters.validate-opmon >>
    jobs:
      - validate-opmon
  validate-jetstream:
    when: 
      or: 
        - << pipeline.parameters.validate-jetstream >>
    jobs:
      - validate-jetstream
  validate-looker:
    when: 
      or: 
        - << pipeline.parameters.validate-looker >>
    jobs:
      - validate-looker
  build-metric-config-parser:
    when: 
      or: 
        - << pipeline.parameters.validate-metric-config-parser >>
    jobs:
      - build-metric-config-parser
  integration-metric-config-parser:
    when: 
      or: 
        - << pipeline.parameters.validate-metric-config-parser >>
    jobs:
      - integration-metric-config-parser
  deploy-metric-config-parser:
    when: 
      or: 
        - << pipeline.parameters.deploy-metric-config-parser >>
    jobs:
      - deploy-metric-config-parser
  rerun-jetstream:
    when: 
      or: 
        - << pipeline.parameters.validate-jetstream >>
    jobs:
      - rerun-jetstream:
          filters:
            branches:
              only: main
  build-docs:
    when: 
      or: 
        - << pipeline.parameters.build-docs >>
    jobs:
      - build-docs:
          filters:
            branches:
              only: main
